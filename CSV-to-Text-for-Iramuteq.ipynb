{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17590618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cells 4 onwards produce different outputs. Only run the cell(s) for the output(s) you want.\n",
    "\n",
    "# this version only takes every nth post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64b94d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\OMars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb1b320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#might'\n"
     ]
    }
   ],
   "source": [
    "pip install -r cluster-requirements.txt  #might be some missing, let me know if so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7fef53c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516836\n",
      "Sample every nth cell, where n = 1\n",
      "df created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (11,15,21,27,29,41,53,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#change filepath to wherever you've stored csv.  Needs fields 'twitter.tweet/text' and 'twitter.tweet/created'\n",
    "\n",
    "\n",
    "file = r'C:\\Users\\OMars\\Documents\\CASM_offline\\Citizens-Advice\\post-issues-w-stakeholders-for-cluster.csv'\n",
    "file = str(file)\n",
    "#print(file)\n",
    "#df = pd.read_csv(file)\n",
    "\n",
    "\n",
    "row_count = 0\n",
    "\n",
    "for row in open(r'C:\\Users\\OMars\\Documents\\CASM_offline\\Citizens-Advice\\post-issues-w-stakeholders-for-cluster.csv', \"r\",encoding='utf-8'):\n",
    "    row_count += 1\n",
    "\n",
    "print(row_count)\n",
    "    \n",
    "n = input('Sample every nth cell, where n = ')\n",
    "n = int(n)\n",
    "\n",
    "#create pandas dataframe from only every nth row from csv - taken from https://stackoverflow.com/questions/53812094/select-every-nth-row-as-a-pandas-dataframe-without-reading-the-entire-file\n",
    "\n",
    "skip = np.arange(row_count)\n",
    "skip = np.delete(skip, np.arange(0, row_count, n))\n",
    "df = pd.read_csv(file, skiprows = skip)\n",
    "df.index.name = 'id'\n",
    "print('df created')\n",
    "\n",
    "#df = df.iloc[::n, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89ee79d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename output? 10000\n"
     ]
    }
   ],
   "source": [
    "#OPTION 1 Produces one file with one header\n",
    "\n",
    "output = input('filename output? ')\n",
    "output = output + '.txt'\n",
    "\n",
    "a = list(df['twitter.tweet/text'])\n",
    "b = '\\n'.join(str(t) for t in a)\n",
    "\n",
    "b = re.sub(r'[^a-zA-Z \\n]+','', b)\n",
    "#b = os.linesep.join([s for s in b.splitlines() if s])\n",
    "#print(b)\n",
    "\n",
    "\n",
    "with open(output, 'w', encoding = 'utf-8') as f:\n",
    "    \n",
    "    f.write('**** *all_text\\n\\n')\n",
    "    f.write(b.lower())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cf7767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 2 : produce one file with separated years\n",
    "\n",
    "df['date'] = df['twitter.tweet/created'].str[:4]\n",
    "\n",
    "with open('post-cluster-test.txt', 'w', encoding = 'utf-8') as f:\n",
    "\n",
    "    for year in range (2017, 2022):\n",
    "        year_str = str(year) \n",
    "        f.write('**** *year_'+year_str+'\\n\\n')\n",
    "        df_temp = df[df['date'] == year]\n",
    "        text = list(df['twitter.tweet/text'])\n",
    "        text = '\\n'.join(str(t) for t in text)\n",
    "        text = re.sub(r'[^a-zA-Z \\n]+','', text)\n",
    "        f.write(text.lower())\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bfd8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 3 : produce separate file for each year\n",
    "\n",
    "df_1 = pd.read_csv(r'C:\\Users\\OMars\\Dropbox\\Oliver Sharing Stuff\\2021 Work\\CASM\\Citizens-Advice\\post-clean-for-clustering.csv')\n",
    "df['date'] = df['twitter.tweet/created'].str[:4]\n",
    "\n",
    "\n",
    "for year in range (2017, 2022):\n",
    "    year_str = str(year)\n",
    "    doc_title = 'post-cluster-'+year_str+'-100k-only-1.txt'\n",
    "    with open(doc_title, 'w', encoding = 'utf-8') as f:\n",
    "        f.write('**** *year_'+year_str+'\\n\\n')\n",
    "        df_temp = df[df['date'] == year]\n",
    "        text = list(df['twitter.tweet/text'])\n",
    "        text = '\\n'.join(str(t) for t in text)\n",
    "        text = re.sub(r'[^a-zA-Z \\n]+','', text)\n",
    "        f.write(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "baad0fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 4: one file with separated years and stopwords removed\n",
    "\n",
    "#define stopword remover\n",
    "# NLTK Stop words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "df['date'] = df'twitter.tweet/created'].str[:4]\n",
    "\n",
    "with open('post-cluster-all-years-nostops-1.txt', 'w', encoding = 'utf-8') as f:\n",
    "\n",
    "    for year in range (2017, 2022):\n",
    "        year_str = str(year) \n",
    "        f.write('**** *year_'+year_str+'\\n\\n')\n",
    "        df_temp = df[df['date'] == year]\n",
    "        text = list(df['twitter.tweet/text'])\n",
    "        text = [word for word in text if word not in stopwords.words('english')]\n",
    "        text = '\\n'.join(str(t) for t in text)\n",
    "        text = re.sub(r'[^a-zA-Z \\n]+','', text)\n",
    "        f.write(text.lower())\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9f1899a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APC\n",
      "                                     twitter.tweet/text     match-column\n",
      "id                                                                      \n",
      "684   @APCOvernight I‚Äôve got a parcel missing, I‚Äôve ...  [@apcovernight]\n",
      "3115  @APCcustserv could someone DM me please lookin...   [@apccustserv]\n",
      "3196  Dear @APCOvernight - no matter how many times ...  [@apcovernight]\n",
      "3466  @Etsy I have been repeatedly ignored by a sell...  [@apcovernight]\n",
      "5215  @APCOvernight Have been awaiting a delivery fr...  [@apcovernight]\n",
      "Amazon\n",
      "                                   twitter.tweet/text match-column\n",
      "id                                                                \n",
      "16  @jasonalba With all the negativity in the worl...  [@amazonuk]\n",
      "23  @winding_sios @AmazonUK Amazon playing it safe...  [@amazonuk]\n",
      "42  @NikoSarcevic @AmazonUK Thanks! Not really hav...  [@amazonuk]\n",
      "59  @PatrickMooney @AmazonHelp @AmazonUK They shou...  [@amazonuk]\n",
      "80  @LimeyPrintmaker @AmazonUK @CalendarClubUK Yea...  [@amazonuk]\n",
      "Collect-Plus\n",
      "                                     twitter.tweet/text    match-column\n",
      "id                                                                     \n",
      "1015  Never using @CollectPlus again. üëéüëéüëé incompeten...  [@collectplus]\n",
      "1419  @CollectPlus two local stores not collecting p...  [@collectplus]\n",
      "2172  Trying to return this package in line with my ...  [@collectplus]\n",
      "2480  @CollectPlus how do I let you know that a coup...  [@collectplus]\n",
      "3651  @sevenstoreHQ i have a return coming back to y...  [@collectplus]\n",
      "DHL\n",
      "                                   twitter.tweet/text     match-column\n",
      "id                                                                    \n",
      "3   @dhlexpressuk dhl gave no notice of delivery.I...  [@dhlexpressuk]\n",
      "17  @dhlexpressuk Hi, I have been expecting a parc...  [@dhlexpressuk]\n",
      "18  @dhlexpressuk needs to try harder so that my g...  [@dhlexpressuk]\n",
      "32  My order is en route from past nine days and t...  [@dhlexpressuk]\n",
      "52  @dhlexpressuk package never arrived, tracking ...  [@dhlexpressuk]\n",
      "DPD\n",
      "                                      twitter.tweet/text        match-column\n",
      "id                                                                          \n",
      "1289   @DPDCustomerCare @DPDgroup_news  I was home, I...  [@dpdcustomercare]\n",
      "7930   @DPD_UK So angry with one of your drivers righ...           [@dpd_uk]\n",
      "10915  @DPDCustomerCare \\nHello, I am waiting for the...  [@dpdcustomercare]\n",
      "11472  @DPDcustomercare  hi I received text this morn...  [@dpdcustomercare]\n",
      "13035  @dpd_support  is this really true, I find it v...  [@dpdcustomercare]\n",
      "DX\n",
      "                                     twitter.tweet/text   match-column\n",
      "id                                                                    \n",
      "1324  @DXdelivery any ETA on my delivery that was sc...  [@dxdelivery]\n",
      "1829  @ejonesjewellers Christ, if I‚Äôd known you were...  [@dxdelivery]\n",
      "1850  @DXdelivery we were meant to have a parcel del...  [@dxdelivery]\n",
      "1853  @DXdelivery Do @ejonesjewellers know how bad y...  [@dxdelivery]\n",
      "1941  @DXdelivery i have package that should arrive ...  [@dxdelivery]\n",
      "Doddle\n",
      "                                      twitter.tweet/text match-column\n",
      "id                                                                   \n",
      "8289   üì¢ We have another great customer case study re...    [@doddle]\n",
      "24384  @Doddle Hi can you tell me where I collect a D...    [@doddle]\n",
      "30455  üì¢ We have another great customer case study re...    [@doddle]\n",
      "42776  @Doddle Can you confirm where I collect my par...    [@doddle]\n",
      "48455  üì¢ We have another great customer case study re...    [@doddle]\n",
      "FedEx\n",
      "                                    twitter.tweet/text    match-column\n",
      "id                                                                    \n",
      "8    @FedExEurope what's going on, my delivery was ...  [@fedexeurope]\n",
      "71   @FedExHelpEU Hi, Can I get help with a package...  [@fedexhelpeu]\n",
      "72   @FedExHelpEU I have an overdue duty and tax pa...  [@fedexhelpeu]\n",
      "100  @idriveaclassic Want to get this one registere...  [@fedexeurope]\n",
      "117  @FedExEurope \\n\\nHow many days did the order a...  [@fedexeurope]\n",
      "Hermes\n",
      "                                   twitter.tweet/text      match-column\n",
      "id                                                                     \n",
      "0   @SiTheGooner84 @Hermesparcels Me & @JamesRaulS...  [@hermesparcels]\n",
      "2   @Hermesparcels still trying to track down a pa...  [@hermesparcels]\n",
      "5   @Hermesparcels I sent the parcel and been tryi...  [@hermesparcels]\n",
      "6   @Bumblebee89098 @Hermesparcels Hi did they los...  [@hermesparcels]\n",
      "10  @Hermesparcels what do I do if a courier didn‚Äô...  [@hermesparcels]\n",
      "HubBox\n",
      "                                       twitter.tweet/text match-column\n",
      "id                                                                    \n",
      "328350  @HubBoxHQ can someone please reply to my email...  [@hubboxhq]\n",
      "InPost\n",
      "                                     twitter.tweet/text match-column\n",
      "id                                                                  \n",
      "496   @InPostUK @Hermesparcels Just to let you know ...  [@inpostuk]\n",
      "593   @InPostUK can I send a parcel locker to locker...  [@inpostuk]\n",
      "1151  @InPostUK What a waste of my life & petrol, tr...  [@inpostuk]\n",
      "1477  @InPostUK just went to drop off a parcel at Mo...  [@inpostuk]\n",
      "2012  @MsMainstay @InPostUK Aah. I gave up on this, ...  [@inpostuk]\n",
      "Interparcel\n",
      "                                    twitter.tweet/text    match-column\n",
      "id                                                                    \n",
      "78   @interparcel Yes please this would be so lovel...  [@interparcel]\n",
      "429  @interparcel FABULOUS! What a great way to sta...  [@interparcel]\n",
      "650    @interparcel How yummy! This would be amazing ü§§  [@interparcel]\n",
      "717                   @interparcel Oh my, yes please ü§û  [@interparcel]\n",
      "890  @interparcel Very generous! I will put it towa...  [@interparcel]\n",
      "P4D\n",
      "                                      twitter.tweet/text match-column\n",
      "id                                                                   \n",
      "1423   Anyone ever thought about using @P4D for shipp...       [@p4d]\n",
      "16019  ùêõùêÆùê≠ ùê∞ùê°ùêöùê≠ ùê†ùê®ùêûùê¨ ùê®ùêß ùê¢ùêß ùê≠ùê°ùêû ùêúùê®ùêßùêúùêûùêßùê≠ùê´ùêöùê≠ùê¢ùê®ùêß ùêúùêöùê¶ùê©?......       [@p4d]\n",
      "23775  @P4D  and @parcelforce 2 companies i will neve...       [@p4d]\n",
      "42607  @P4D Ordered a collection/delivery in the UK o...       [@p4d]\n",
      "50678  @P4D how long does it take for a damaged in tr...       [@p4d]\n",
      "Parcel-Broker\n",
      "                                       twitter.tweet/text     match-column\n",
      "id                                                                        \n",
      "116651  Has anyone seen this package? It was put on a ...  [@parcelbroker]\n",
      "306216  @parcelbroker @EllieJaneTaylor @richardosman @...  [@parcelbroker]\n",
      "306271  @parcelbroker @EllieJaneTaylor @richardosman @...  [@parcelbroker]\n",
      "306545  @parcelbroker @EllieJaneTaylor @richardosman @...  [@parcelbroker]\n",
      "306872  @parcelbroker @EllieJaneTaylor @richardosman @...  [@parcelbroker]\n",
      "Parcel-Monkey\n",
      "                                     twitter.tweet/text     match-column\n",
      "id                                                                      \n",
      "373   @AmazonHelp So after talking to Wesley and the...  [@parcelmonkey]\n",
      "487   @parcelmonkey I‚Äôve been charged twice for a pa...  [@parcelmonkey]\n",
      "512   @parcelmonkey are you called parcel Monkey bec...  [@parcelmonkey]\n",
      "629   @BeeNubian @sibasichillies Use @parcelmonkey \\...  [@parcelmonkey]\n",
      "3384  I don't usually do endorsements, but @parcelmo...  [@parcelmonkey]\n",
      "Parcel2Go\n",
      "                                    twitter.tweet/text  match-column\n",
      "id                                                                  \n",
      "219  @Mrz__Black @Parcel2Go @Hermesparcels Such a m...  [@parcel2go]\n",
      "478  @Parcel2Go I have reported the #parcel 8024948...  [@parcel2go]\n",
      "601  @TworandN @BritEuropa Perhaps you just need to...  [@parcel2go]\n",
      "652  @ManxMTB @Jay6337 @TworandN Oh he's such a fib...  [@parcel2go]\n",
      "690  @Parcel2Go I‚Äôve sent you a few emails regardin...  [@parcel2go]\n",
      "ParcelCompare\n",
      "                                     twitter.tweet/text      match-column\n",
      "id                                                                       \n",
      "1074  @ParcelCompare just wasted an hour of my time ...  [@parcelcompare]\n",
      "1160  @ParcelCompare it‚Äôs been 2 weeks come on can s...  [@parcelcompare]\n",
      "1288  @ParcelCompare Hi. I have a Hermes package tha...  [@parcelcompare]\n",
      "1369  .@ParcelCompare I am incredibly disappointed w...  [@parcelcompare]\n",
      "1437  @ParcelCompare Yet another issue. Top one was ...  [@parcelcompare]\n",
      "ParcelHero\n",
      "                                     twitter.tweet/text   match-column\n",
      "id                                                                    \n",
      "570   @SLyons16952240 @ParcelHero It‚Äôs awful service...  [@parcelhero]\n",
      "580   @ParcelHero @UPS how come a parcel I sent last...  [@parcelhero]\n",
      "712   @ParcelHero Now January 2nd and still the parc...  [@parcelhero]\n",
      "2177  @ParcelHero I provided you with everything, bu...  [@parcelhero]\n",
      "2206  @ParcelHero I have contacted you through many ...  [@parcelhero]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parcelforce\n",
      "                                    twitter.tweet/text    match-column\n",
      "id                                                                    \n",
      "1    @parcelforce been trying to change delivery ad...  [@parcelforce]\n",
      "30   @parcelforce So I had a parcel sent yesterday ...  [@parcelforce]\n",
      "79   @parcelforce Hello sent you a DM but still hav...  [@parcelforce]\n",
      "106  @parcelforce It really is no wonder you are al...  [@parcelforce]\n",
      "134  Actually, on checking the tracking code using ...  [@parcelforce]\n",
      "Parcelly\n",
      "                                       twitter.tweet/text match-column\n",
      "id                                                                    \n",
      "8252    @parcelly are you guys seriously lying about y...  [@parcelly]\n",
      "65028   @parcelly @atmosfair The app says it‚Äôs invalua...  [@parcelly]\n",
      "68770   @parcelly what is this and why does it happen ...  [@parcelly]\n",
      "125622  'We already see the emergence of mandatory cha...  [@parcelly]\n",
      "126878  We have some exciting news to announce! @parce...  [@parcelly]\n",
      "Pass-My-Parcel\n",
      "Empty DataFrame\n",
      "Columns: [twitter.tweet/text, match-column]\n",
      "Index: []\n",
      "Post-Office\n",
      "                                   twitter.tweet/text   match-column\n",
      "id                                                                  \n",
      "4   @PostOffice please can someone tell me where m...  [@postoffice]\n",
      "19  @gently_bimbling @Kevcrq1975 @Andrew_Adonis @m...  [@postoffice]\n",
      "24  @PostOffice I went into my local post office t...  [@postoffice]\n",
      "33  @IndiaPostOffice @BangalorePost \\nThis huge qu...  [@postoffice]\n",
      "34  @IndiaPostOffice @BangalorePost \\nThis huge qu...  [@postoffice]\n",
      "Royal-Mail\n",
      "                                   twitter.tweet/text  \\\n",
      "id                                                      \n",
      "9   Amazing customer service yesterday at the @Roy...   \n",
      "12  @RoyalMailHelp Hi it‚Äôs been 11 days since I se...   \n",
      "14  @jackboskett @HattonsModels @RoyalMail @hornby...   \n",
      "15  Any idea why payments aren't being accepted on...   \n",
      "20  @jackboskett @J70JDV @HattonsModels @RoyalMail...   \n",
      "\n",
      "                    match-column  \n",
      "id                                \n",
      "9               [@royalmailhelp]  \n",
      "12              [@royalmailhelp]  \n",
      "14                  [@royalmail]  \n",
      "15  [@royalmailhelp, @royalmail]  \n",
      "20                  [@royalmail]  \n",
      "TNT\n",
      "                                    twitter.tweet/text      match-column\n",
      "id                                                                      \n",
      "88   @TNTUKOfficial you are a joke. Waited in all d...  [@tntukofficial]\n",
      "226  @Noseytoes @TNTUKCare I had the same issue wit...      [@tntukcare]\n",
      "287  @TNTUKOfficial Hi there, I sent my parcel to S...  [@tntukofficial]\n",
      "357  Thank you @TNTUKCare excellent service in the ...      [@tntukcare]\n",
      "978  @TNTUKCare  dreadful communication service fro...      [@tntukcare]\n",
      "Tuffnells\n",
      "                                     twitter.tweet/text  match-column\n",
      "id                                                                   \n",
      "5084  @Tuffnells used to our carriers melting down p...  [@tuffnells]\n",
      "8421  @Tuffnells I took delivery yesterday but recei...  [@tuffnells]\n",
      "8801  Disgusting service received from @interparcel ...  [@tuffnells]\n",
      "8816  @Tuffnells I was awaiting a 2-carpet delivery ...  [@tuffnells]\n",
      "9510  @luxuryhomedecco @Tuffnells @YODELhell Hello, ...  [@tuffnells]\n",
      "UK-Mail\n",
      "                                      twitter.tweet/text       match-column\n",
      "id                                                                         \n",
      "10097  Experience of a parcel being delivered by @off...  [@officialukmail]\n",
      "10783  @stokedpapa 1st package we‚Äôve had delivered by...  [@officialukmail]\n",
      "10859  @officialUKMail It's now 24hrs since the promi...  [@officialukmail]\n",
      "20704  @officialUKMail no collection slot issued toda...  [@officialukmail]\n",
      "30460  @officialUKMail I missed delivery today. Could...  [@officialukmail]\n",
      "UPS\n",
      "                                   twitter.tweet/text match-column\n",
      "id                                                                \n",
      "41  @HUGOBOSS my goods have still not came from th...    [@ups_uk]\n",
      "57  @UPS_UK Due to your incompetency and not deliv...    [@ups_uk]\n",
      "70  @UPS_UK I'm just hoping you bring me my packag...    [@ups_uk]\n",
      "77  Anyone else still not got their OG‚Äôs from the ...    [@ups_uk]\n",
      "86  @UPS_UK your company‚Äôs a bad joke. My parcel i...    [@ups_uk]\n",
      "Yodel\n",
      "                                    twitter.tweet/text    match-column\n",
      "id                                                                    \n",
      "7    @YodelOnline Hi i have a parcel for next week,...  [@yodelonline]\n",
      "50   @YodelOnline Seems every delivery Yodel make f...  [@yodelonline]\n",
      "51   @YodelOnline @TheBeerHawk Good morning can you...  [@yodelonline]\n",
      "69   @scribbles78 @YodelOnline @TheBeerHawk Not the...  [@yodelonline]\n",
      "168  @YodelOnline your driver has delivered to the ...  [@yodelonline]\n",
      "iPostParcels\n",
      "                                       twitter.tweet/text     match-column\n",
      "id                                                                        \n",
      "148780  Hey https://t.co/LUDpKr4wzu(@ipostparcels), th...  [@ipostparcels]\n",
      "168288  @ipostparcels iPost Parcels - useless!! 5 week...  [@ipostparcels]\n",
      "345735  @ipostparcels all the way! In 8 years only had...  [@ipostparcels]\n"
     ]
    }
   ],
   "source": [
    "#option 5: split by companies\n",
    "\n",
    "companies = ('APC', 'Amazon', 'Collect-Plus', 'DHL', 'DPD', 'DX', 'Doddle', 'FedEx', 'Hermes', 'HubBox', 'InPost', 'Interparcel', 'P4D', 'Parcel-Broker', 'Parcel-Monkey', 'Parcel2Go', 'ParcelCompare', 'ParcelHero', 'Parcelforce', 'Parcelly', 'Pass-My-Parcel', 'Post-Office', 'Royal-Mail', 'TNT', 'Tuffnells', 'UK-Mail', 'UPS', 'Yodel', 'iPostParcels')\n",
    "\n",
    "#create a new dataframe which only has matches plus text\n",
    "\n",
    "with open('post-cluster-all-companies-all.txt', 'w', encoding = 'utf-8') as f:   \n",
    "\n",
    "    for company in companies:\n",
    "\n",
    "        thestring = company+'-matches'\n",
    "        df_matches = df.loc[:,df.columns.str.endswith(thestring)]\n",
    "        df_2 = pd.concat([df[\"twitter.tweet/text\"], df_matches], axis=1)\n",
    "        df_2.rename(columns = {list(df_2)[1]: 'match-column'}, inplace = True)\n",
    "        df_3 = df_2[~df_2['match-column'].isnull()]\n",
    "        print(company)\n",
    "        print(df_3.head())\n",
    "        f.write('**** *company_'+company.lower()+'\\n\\n')\n",
    "        text = list(df_3['twitter.tweet/text'])\n",
    "        text = '\\n'.join(str(t) for t in text)\n",
    "        text = re.sub(r'[^a-zA-Z \\n ]+','', text)\n",
    "        f.write(text.lower())\n",
    "        f.write('\\n\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bbd60b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
