{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17590618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cells 4 onwards produce different outputs. Only run the cell(s) for the output(s) you want.\n",
    "\n",
    "# this version only takes every nth post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64b94d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\OMars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb1b320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#might'\n"
     ]
    }
   ],
   "source": [
    "pip install -r cluster-requirements.txt  #might be some missing, let me know if so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fef53c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\JoshSmith\\Documents\\Scripts\\cluster-viz\\CSV-to-Text-for-Iramuteq.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JoshSmith/Documents/Scripts/cluster-viz/CSV-to-Text-for-Iramuteq.ipynb#ch0000003?line=6'>7</a>\u001b[0m output_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_dir, \u001b[39m'\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JoshSmith/Documents/Scripts/cluster-viz/CSV-to-Text-for-Iramuteq.ipynb#ch0000003?line=7'>8</a>\u001b[0m csv_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_dir, csv_name)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/JoshSmith/Documents/Scripts/cluster-viz/CSV-to-Text-for-Iramuteq.ipynb#ch0000003?line=11'>12</a>\u001b[0m doclengths \u001b[39m=\u001b[39m [\u001b[39mlen\u001b[39m(r[text_field]) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mopen\u001b[39m(csv_path, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JoshSmith/Documents/Scripts/cluster-viz/CSV-to-Text-for-Iramuteq.ipynb#ch0000003?line=12'>13</a>\u001b[0m row_count \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(doclengths)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JoshSmith/Documents/Scripts/cluster-viz/CSV-to-Text-for-Iramuteq.ipynb#ch0000003?line=13'>14</a>\u001b[0m avg_doc_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39msum\u001b[39m(doclengths) \u001b[39m/\u001b[39m row_count)\n",
      "\u001b[1;32mc:\\Users\\JoshSmith\\Documents\\Scripts\\cluster-viz\\CSV-to-Text-for-Iramuteq.ipynb Cell 4'\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JoshSmith/Documents/Scripts/cluster-viz/CSV-to-Text-for-Iramuteq.ipynb#ch0000003?line=6'>7</a>\u001b[0m output_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_dir, \u001b[39m'\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JoshSmith/Documents/Scripts/cluster-viz/CSV-to-Text-for-Iramuteq.ipynb#ch0000003?line=7'>8</a>\u001b[0m csv_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_dir, csv_name)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/JoshSmith/Documents/Scripts/cluster-viz/CSV-to-Text-for-Iramuteq.ipynb#ch0000003?line=11'>12</a>\u001b[0m doclengths \u001b[39m=\u001b[39m [\u001b[39mlen\u001b[39m(r[text_field]) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mopen\u001b[39m(csv_path, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JoshSmith/Documents/Scripts/cluster-viz/CSV-to-Text-for-Iramuteq.ipynb#ch0000003?line=12'>13</a>\u001b[0m row_count \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(doclengths)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JoshSmith/Documents/Scripts/cluster-viz/CSV-to-Text-for-Iramuteq.ipynb#ch0000003?line=13'>14</a>\u001b[0m avg_doc_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39msum\u001b[39m(doclengths) \u001b[39m/\u001b[39m row_count)\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# Change csv_name, which we're expecting to be stored in the 'data' subdir. \n",
    "# Needs fields 'twitter.tweet/text' and 'twitter.tweet/created'\n",
    "csv_name = 'post-issues-w-stakeholders-for-cluster.csv'\n",
    "text_field = 'twitter.tweet/text'\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "output_dir = os.path.join(data_dir, 'outputs')\n",
    "csv_path = os.path.join(data_dir, csv_name)\n",
    "\n",
    "with open(csv_path, \"r\", encoding='utf-8') as csv_f:\n",
    "    reader = csv.DictReader(csv_f)\n",
    "    doclengths = [len(row[text_field]) for row in reader]\n",
    "\n",
    "row_count = len(doclengths)\n",
    "avg_doc_size = int(sum(doclengths) / row_count)\n",
    "\n",
    "print(\"{} rows in {}\".format(row_count, csv_name))\n",
    "print(\"Average document length is {}\".format(avg_doc_size))\n",
    "\n",
    "# Define a default for n - remove to prompt every time\n",
    "n = 50\n",
    "if not n:  \n",
    "    n = input('Sample every nth cell, where n = ')\n",
    "    n = int(n)\n",
    "print(\"sampling 1 in every {} row(s)\".format(n))\n",
    "\n",
    "# create pandas dataframe from only every nth row from csv - \n",
    "# taken from https://stackoverflow.com/questions/53812094/select-every-nth-row-as-a-pandas-dataframe-without-reading-the-entire-file\n",
    "\n",
    "skip = np.arange(row_count)\n",
    "skip = np.delete(skip, np.arange(0, row_count, n))\n",
    "df = pd.read_csv(csv_path, skiprows = skip)\n",
    "df.index.name = 'id'\n",
    "print('df created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c694fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classify/post-classifier-v3-29-03-18-issue</th>\n",
       "      <th>classify/post-classifier-v3-29-03-18-not-issue</th>\n",
       "      <th>stakeholder/APC</th>\n",
       "      <th>stakeholder/APC-matches</th>\n",
       "      <th>stakeholder/Amazon</th>\n",
       "      <th>stakeholder/Amazon-matches</th>\n",
       "      <th>stakeholder/Collect-Plus</th>\n",
       "      <th>stakeholder/Collect-Plus-matches</th>\n",
       "      <th>stakeholder/DHL</th>\n",
       "      <th>stakeholder/DHL-matches</th>\n",
       "      <th>...</th>\n",
       "      <th>stakeholder/UK-Mail-matches</th>\n",
       "      <th>stakeholder/UPS</th>\n",
       "      <th>stakeholder/UPS-matches</th>\n",
       "      <th>stakeholder/Yodel</th>\n",
       "      <th>stakeholder/Yodel-matches</th>\n",
       "      <th>stakeholder/iPostParcels</th>\n",
       "      <th>stakeholder/iPostParcels-matches</th>\n",
       "      <th>twitter.tweet/created</th>\n",
       "      <th>twitter.tweet/id</th>\n",
       "      <th>twitter.tweet/text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-01T08:00:53.000Z</td>\n",
       "      <td>1344916490655592448</td>\n",
       "      <td>Testing REST APIs using Postman free download ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-01T10:16:44.000Z</td>\n",
       "      <td>1344950680411365379</td>\n",
       "      <td>For the last two weeks @RoyalMailHelp have sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-01T11:03:44.000Z</td>\n",
       "      <td>1344962505643335681</td>\n",
       "      <td>@RoyalMail Oh the sunlit uplands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-01T11:48:23.000Z</td>\n",
       "      <td>1344973741533573121</td>\n",
       "      <td>@Linda_Marric @parcelforce At the risk of bomb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-01T12:24:19.000Z</td>\n",
       "      <td>1344982784905981952</td>\n",
       "      <td>@PostOffice Happy New Year, I paid £7.50 for n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023</th>\n",
       "      <td>issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-10-28T11:59:43.000Z</td>\n",
       "      <td>1453692956624527365</td>\n",
       "      <td>@hermesparcels   for the last 3 days my parcel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8024</th>\n",
       "      <td>issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-10-28T12:19:43.000Z</td>\n",
       "      <td>1453697987524300805</td>\n",
       "      <td>@Hermesparcels how on earth do i speak to a hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8025</th>\n",
       "      <td>issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-10-28T12:41:38.000Z</td>\n",
       "      <td>1453703503008915459</td>\n",
       "      <td>@connollyjon @Hermesparcels Had the misfortune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8026</th>\n",
       "      <td>issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-10-28T12:58:12.000Z</td>\n",
       "      <td>1453707674953134084</td>\n",
       "      <td>FFS that’s the birthday present we were giving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8027</th>\n",
       "      <td>issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-10-28T13:24:00.000Z</td>\n",
       "      <td>1453714165416140801</td>\n",
       "      <td>@parcelforce tracking shows parcel ‘awaiting p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8028 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     classify/post-classifier-v3-29-03-18-issue  \\\n",
       "id                                                \n",
       "0                                         issue   \n",
       "1                                         issue   \n",
       "2                                         issue   \n",
       "3                                         issue   \n",
       "4                                         issue   \n",
       "...                                         ...   \n",
       "8023                                      issue   \n",
       "8024                                      issue   \n",
       "8025                                      issue   \n",
       "8026                                      issue   \n",
       "8027                                      issue   \n",
       "\n",
       "      classify/post-classifier-v3-29-03-18-not-issue  stakeholder/APC  \\\n",
       "id                                                                      \n",
       "0                                                NaN            False   \n",
       "1                                                NaN            False   \n",
       "2                                                NaN            False   \n",
       "3                                                NaN            False   \n",
       "4                                                NaN            False   \n",
       "...                                              ...              ...   \n",
       "8023                                             NaN            False   \n",
       "8024                                             NaN            False   \n",
       "8025                                             NaN            False   \n",
       "8026                                             NaN            False   \n",
       "8027                                             NaN            False   \n",
       "\n",
       "     stakeholder/APC-matches  stakeholder/Amazon stakeholder/Amazon-matches  \\\n",
       "id                                                                            \n",
       "0                        NaN               False                        NaN   \n",
       "1                        NaN               False                        NaN   \n",
       "2                        NaN               False                        NaN   \n",
       "3                        NaN               False                        NaN   \n",
       "4                        NaN               False                        NaN   \n",
       "...                      ...                 ...                        ...   \n",
       "8023                     NaN               False                        NaN   \n",
       "8024                     NaN               False                        NaN   \n",
       "8025                     NaN               False                        NaN   \n",
       "8026                     NaN               False                        NaN   \n",
       "8027                     NaN               False                        NaN   \n",
       "\n",
       "      stakeholder/Collect-Plus stakeholder/Collect-Plus-matches  \\\n",
       "id                                                                \n",
       "0                        False                              NaN   \n",
       "1                        False                              NaN   \n",
       "2                        False                              NaN   \n",
       "3                        False                              NaN   \n",
       "4                        False                              NaN   \n",
       "...                        ...                              ...   \n",
       "8023                     False                              NaN   \n",
       "8024                     False                              NaN   \n",
       "8025                     False                              NaN   \n",
       "8026                     False                              NaN   \n",
       "8027                     False                              NaN   \n",
       "\n",
       "      stakeholder/DHL stakeholder/DHL-matches  ...  \\\n",
       "id                                             ...   \n",
       "0               False                     NaN  ...   \n",
       "1               False                     NaN  ...   \n",
       "2               False                     NaN  ...   \n",
       "3               False                     NaN  ...   \n",
       "4               False                     NaN  ...   \n",
       "...               ...                     ...  ...   \n",
       "8023            False                     NaN  ...   \n",
       "8024            False                     NaN  ...   \n",
       "8025            False                     NaN  ...   \n",
       "8026            False                     NaN  ...   \n",
       "8027            False                     NaN  ...   \n",
       "\n",
       "      stakeholder/UK-Mail-matches stakeholder/UPS  stakeholder/UPS-matches  \\\n",
       "id                                                                           \n",
       "0                             NaN           False                      NaN   \n",
       "1                             NaN           False                      NaN   \n",
       "2                             NaN           False                      NaN   \n",
       "3                             NaN           False                      NaN   \n",
       "4                             NaN           False                      NaN   \n",
       "...                           ...             ...                      ...   \n",
       "8023                          NaN           False                      NaN   \n",
       "8024                          NaN           False                      NaN   \n",
       "8025                          NaN           False                      NaN   \n",
       "8026                          NaN           False                      NaN   \n",
       "8027                          NaN           False                      NaN   \n",
       "\n",
       "     stakeholder/Yodel  stakeholder/Yodel-matches  stakeholder/iPostParcels  \\\n",
       "id                                                                            \n",
       "0                False                        NaN                     False   \n",
       "1                False                        NaN                     False   \n",
       "2                False                        NaN                     False   \n",
       "3                False                        NaN                     False   \n",
       "4                False                        NaN                     False   \n",
       "...                ...                        ...                       ...   \n",
       "8023             False                        NaN                     False   \n",
       "8024             False                        NaN                     False   \n",
       "8025             False                        NaN                     False   \n",
       "8026             False                        NaN                     False   \n",
       "8027             False                        NaN                     False   \n",
       "\n",
       "      stakeholder/iPostParcels-matches     twitter.tweet/created  \\\n",
       "id                                                                 \n",
       "0                                  NaN  2021-01-01T08:00:53.000Z   \n",
       "1                                  NaN  2021-01-01T10:16:44.000Z   \n",
       "2                                  NaN  2021-01-01T11:03:44.000Z   \n",
       "3                                  NaN  2021-01-01T11:48:23.000Z   \n",
       "4                                  NaN  2021-01-01T12:24:19.000Z   \n",
       "...                                ...                       ...   \n",
       "8023                               NaN  2021-10-28T11:59:43.000Z   \n",
       "8024                               NaN  2021-10-28T12:19:43.000Z   \n",
       "8025                               NaN  2021-10-28T12:41:38.000Z   \n",
       "8026                               NaN  2021-10-28T12:58:12.000Z   \n",
       "8027                               NaN  2021-10-28T13:24:00.000Z   \n",
       "\n",
       "         twitter.tweet/id                                 twitter.tweet/text  \n",
       "id                                                                            \n",
       "0     1344916490655592448  Testing REST APIs using Postman free download ...  \n",
       "1     1344950680411365379  For the last two weeks @RoyalMailHelp have sai...  \n",
       "2     1344962505643335681                   @RoyalMail Oh the sunlit uplands  \n",
       "3     1344973741533573121  @Linda_Marric @parcelforce At the risk of bomb...  \n",
       "4     1344982784905981952  @PostOffice Happy New Year, I paid £7.50 for n...  \n",
       "...                   ...                                                ...  \n",
       "8023  1453692956624527365  @hermesparcels   for the last 3 days my parcel...  \n",
       "8024  1453697987524300805  @Hermesparcels how on earth do i speak to a hu...  \n",
       "8025  1453703503008915459  @connollyjon @Hermesparcels Had the misfortune...  \n",
       "8026  1453707674953134084  FFS that’s the birthday present we were giving...  \n",
       "8027  1453714165416140801  @parcelforce tracking shows parcel ‘awaiting p...  \n",
       "\n",
       "[8028 rows x 63 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89ee79d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename output? 10000\n"
     ]
    }
   ],
   "source": [
    "#OPTION 1 Produces one file with one header\n",
    "\n",
    "output = input('filename output? ')\n",
    "output = output + '.txt'\n",
    "\n",
    "a = list(df['twitter.tweet/text'])\n",
    "b = '\\n'.join(str(t) for t in a)\n",
    "\n",
    "b = re.sub(r'[^a-zA-Z \\n]+','', b)\n",
    "#b = os.linesep.join([s for s in b.splitlines() if s])\n",
    "#print(b)\n",
    "\n",
    "\n",
    "with open(output, 'w', encoding = 'utf-8') as f:\n",
    "    \n",
    "    f.write('**** *all_text\\n\\n')\n",
    "    f.write(b.lower())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cf7767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 2 : produce one file with separated years\n",
    "\n",
    "df['date'] = df['twitter.tweet/created'].str[:4]\n",
    "\n",
    "with open('post-cluster-test.txt', 'w', encoding = 'utf-8') as f:\n",
    "\n",
    "    for year in range (2017, 2022):\n",
    "        year_str = str(year) \n",
    "        f.write('**** *year_'+year_str+'\\n\\n')\n",
    "        df_temp = df[df['date'] == year]\n",
    "        text = list(df['twitter.tweet/text'])\n",
    "        text = '\\n'.join(str(t) for t in text)\n",
    "        text = re.sub(r'[^a-zA-Z \\n]+','', text)\n",
    "        f.write(text.lower())\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bfd8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 3 : produce separate file for each year\n",
    "\n",
    "df_1 = pd.read_csv(r'C:\\Users\\OMars\\Dropbox\\Oliver Sharing Stuff\\2021 Work\\CASM\\Citizens-Advice\\post-clean-for-clustering.csv')\n",
    "df['date'] = df['twitter.tweet/created'].str[:4]\n",
    "\n",
    "\n",
    "for year in range (2017, 2022):\n",
    "    year_str = str(year)\n",
    "    doc_title = 'post-cluster-'+year_str+'-100k-only-1.txt'\n",
    "    with open(doc_title, 'w', encoding = 'utf-8') as f:\n",
    "        f.write('**** *year_'+year_str+'\\n\\n')\n",
    "        df_temp = df[df['date'] == year]\n",
    "        text = list(df['twitter.tweet/text'])\n",
    "        text = '\\n'.join(str(t) for t in text)\n",
    "        text = re.sub(r'[^a-zA-Z \\n]+','', text)\n",
    "        f.write(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "baad0fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 4: one file with separated years and stopwords removed\n",
    "\n",
    "#define stopword remover\n",
    "# NLTK Stop words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "df['date'] = df'twitter.tweet/created'].str[:4]\n",
    "\n",
    "with open('post-cluster-all-years-nostops-1.txt', 'w', encoding = 'utf-8') as f:\n",
    "\n",
    "    for year in range (2017, 2022):\n",
    "        year_str = str(year) \n",
    "        f.write('**** *year_'+year_str+'\\n\\n')\n",
    "        df_temp = df[df['date'] == year]\n",
    "        text = list(df['twitter.tweet/text'])\n",
    "        text = [word for word in text if word not in stopwords.words('english')]\n",
    "        text = '\\n'.join(str(t) for t in text)\n",
    "        text = re.sub(r'[^a-zA-Z \\n]+','', text)\n",
    "        f.write(text.lower())\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f1899a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Option 5: split by companies.\n",
    "# Creates two types of files:\n",
    "# An 'everything file', containing all mentions of any company...\n",
    "everything_filename = \"all_text_by_companies.txt\"\n",
    "# ...and a bunch of company specific files, containing mentions of each.\n",
    "company_filename_template = \"company_mentions_{}.txt\"\n",
    "\n",
    "companies = ('APC', 'Amazon', 'Collect-Plus', 'DHL', 'DPD', 'DX', 'Doddle', \n",
    "             'FedEx', 'Hermes', 'HubBox', 'InPost', 'Interparcel', 'P4D', \n",
    "             'Parcel-Broker', 'Parcel-Monkey', 'Parcel2Go', 'ParcelCompare', \n",
    "             'ParcelHero', 'Parcelforce', 'Parcelly', 'Pass-My-Parcel', \n",
    "             'Post-Office', 'Royal-Mail', 'TNT', 'Tuffnells', 'UK-Mail', \n",
    "             'UPS', 'Yodel', 'iPostParcels')\n",
    "\n",
    "\n",
    "# Create a new dataframe which only has matches plus text\n",
    "def write_company_data_to_file(f):\n",
    "    f.write('**** *company_'+company.lower()+'\\n\\n')\n",
    "    text = list(df_3['twitter.tweet/text'])\n",
    "    text = '\\n'.join(str(t) for t in text)\n",
    "    text = re.sub(r'[^a-zA-Z \\n ]+','', text)\n",
    "    f.write(text.lower())\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "for i, company in enumerate(companies):\n",
    "\n",
    "    # Look for a boolean field written by M52\n",
    "    company_tag = company+'-matches'\n",
    "    \n",
    "    # Pick out rows from df (created above) which contain our tag\n",
    "    df_matches = df.loc[:,df.columns.str.endswith(company_tag)]\n",
    "\n",
    "    df_2 = pd.concat([df[\"twitter.tweet/text\"], df_matches], axis=1)\n",
    "    df_2.rename(columns = {list(df_2)[1]: 'match-column'}, inplace = True)\n",
    "    \n",
    "    df_3 = df_2[~df_2['match-column'].isnull()]\n",
    "\n",
    "    # Append to everything file (or overwrite if this is the first company)\n",
    "    if i == 0:\n",
    "        write_mode = 'w'\n",
    "    else: \n",
    "        write_mode = 'a'\n",
    "\n",
    "    with open(os.path.join(output_dir, everything_filename), write_mode) as ef:\n",
    "        write_company_data_to_file(ef)\n",
    "    \n",
    "    # Write to company specific file\n",
    "    company_filename = company_filename_template.format(company)\n",
    "    with open(os.path.join(output_dir, company_filename), 'w') as cf:\n",
    "        write_company_data_to_file(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bbd60b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
